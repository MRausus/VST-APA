{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1c0cfe",
   "metadata": {},
   "source": [
    "# Video Swin Transformers in Pain Detection\n",
    "## A Comprehensive Evaluation of Effectiveness, Generalizability, and Explainability\n",
    "\n",
    "This notebook contains the code implementation for the paper *Video Swin Transformers in Pain Detection: A Comprehensive Evaluation of Effectiveness, Generalizability, and Explainability*. We evaluate the effectiveness of Video Swin Transformers (VST) in automated pain detection, highlight their generalizability across datasets, and offer insights into the explainability of model decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b348ab",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60405d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, sampler, DataLoader, WeightedRandomSampler\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchvision.io import read_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import video as video_torch\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "import csv\n",
    "from time import time\n",
    "from itertools import product\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Configure device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa030e6-ba47-472d-b56b-d09be5e22eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIG\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 16\n",
    "HYPE_TUNING = True\n",
    "OPTI = \"adam\"\n",
    "WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef634a4-9f5b-4dd3-abd9-935d8c84a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-existing files\n",
    "no_filenames = ['tv095t2aeunaff001', 'tv095t2aeunaff002','tv095t2aeunaff003','tv095t2aeunaff004','tv095t2aeunaff005','tv095t2aeunaff006','tv095t2aeunaff007']\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Resize((224,224))                                         \n",
    "         ]\n",
    "    )\n",
    "\n",
    "# 5 folds\n",
    "la = [\"bn080\", \"mg101\", \"aa048\", \"jh043\", \"jh123\"]\n",
    "lb = [\"dn124\", \"vw121\", \"fn059\", \"dr052\", \"ll042\"]\n",
    "lc = [\"jk103\", \"jl047\", \"ch092\", \"jy115\", \"bg096\"]\n",
    "ld = [\"bm049\", \"kz120\", \"th108\", \"tv095\", \"ib109\"]\n",
    "le = [\"nm106\", \"mg066\", \"hs107\", \"gf097\", \"ak064\"]\n",
    "\n",
    "folds = [la, lb, lc, ld, le]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72268bb9",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Load the UNBC McMaster and BioVid datasets, and preprocess them for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5acd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset for UNBC on frame-lvl\n",
    "class FramesDataset(Dataset):\n",
    "    def __init__(self, mode, test_groups ,transform=None):\n",
    "        ## UNBC lables file\n",
    "        dataset_df = pd.read_csv(\"<PATH>/modified_label_UNBC.csv\")\n",
    "        # delete non existing files\n",
    "        frames_to_delete = [i for i in range(1, 8)]\n",
    "        self.dataset_file = dataset_df[~((dataset_df['participant_id'] == 'tv095') & (dataset_df['video_id'] == 't2aeunaff') & (dataset_df['frame_number'].isin(frames_to_delete)))]\n",
    "\n",
    "        if mode == \"train\":\n",
    "          # put all filesnames from csv which have not the test groups\n",
    "            self.frames_label_df = self.dataset_file[~self.dataset_file['participant_id'].isin(test_groups)]\n",
    "            #self.frames_label_df = self.frames_label_df[:20]\n",
    "\n",
    "        elif mode == \"test\":\n",
    "          # put all filesnames from csv which have not the test groups\n",
    "            self.frames_label_df = self.dataset_file[self.dataset_file['participant_id'].isin(test_groups)]\n",
    "            #self.frames_label_df = self.frames_label_df[:20]\n",
    "        else:\n",
    "            sys.exit(\"mode not correct\")\n",
    "\n",
    "\n",
    "        self.transform = transform\n",
    "        self.ps = len(self.frames_label_df[self.frames_label_df['Label'] == 1])\n",
    "        self.ns = len(self.frames_label_df) - self.ps\n",
    "\n",
    "        self.frames_label_df['weight'] = self.frames_label_df['Label'].apply(lambda x: self.ps if x == 0 else self.ns)\n",
    "        self.labels = self.frames_label_df['Label']\n",
    "        self.weight = self.frames_label_df['weight'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames_label_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.frames_label_df.iloc[idx]\n",
    "        frame_idx = row['frame_number']\n",
    "        video_name = row['participant_id'] + row['video_id']\n",
    "        filename = video_name + str(frame_idx).zfill(3)\n",
    "        frame_path = '<PATH>/Images_Original/' + row['participant_id'] + '/' + video_name + '/' + filename + '.png'\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            frame = transform(frame)\n",
    "        label = self.frames_label_df.iloc[idx]['Label']\n",
    "\n",
    "        return frame, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ee89eb-ea5c-49ab-8efc-ff026da01b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset for UNBC on video-lvl\n",
    "class VideoFramesDataset(Dataset):\n",
    "    def __init__(self, mode, test_groups ,transform=None):\n",
    "\n",
    "        dataset_df = pd.read_csv(\"<PATH>/modified_label_UNBC.csv\")\n",
    "        # delete non existing files\n",
    "        frames_to_delete = [i for i in range(1, 8)]\n",
    "        self.dataset_file = dataset_df[~((dataset_df['participant_id'] == 'tv095') & (dataset_df['video_id'] == 't2aeunaff') & (dataset_df['frame_number'].isin(frames_to_delete)))]\n",
    "\n",
    "        if mode == \"train\":\n",
    "          # put all filesnames from csv which have not the test groups\n",
    "            self.frames_label_df = self.dataset_file[~self.dataset_file['participant_id'].isin(test_groups)]\n",
    "            self.frames_label_df = self.frames_label_df[:20]\n",
    "\n",
    "        elif mode == \"test\":\n",
    "          # put all filesnames from csv which have not the test groups\n",
    "            self.frames_label_df = self.dataset_file[self.dataset_file['participant_id'].isin(test_groups)]\n",
    "            self.frames_label_df = self.frames_label_df[:20]\n",
    "        else:\n",
    "            sys.exit(\"mode not correct\")\n",
    "        self.transform = transform\n",
    "        self.ps = len(self.frames_label_df[self.frames_label_df['Label'] == 1])\n",
    "        self.ns = len(self.frames_label_df) - self.ps\n",
    "\n",
    "        self.frames_label_df['weight'] = self.frames_label_df['Label'].apply(lambda x: self.ps if x == 0 else self.ns)\n",
    "        self.labels = self.frames_label_df['Label']\n",
    "        self.weight = self.frames_label_df['weight'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frames_label_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.frames_label_df.iloc[idx]\n",
    "        frame_idx = row['frame_number']\n",
    "        start_idx = max(1, frame_idx - 3)\n",
    "        end_idx = frame_idx + 1\n",
    "        frames = []\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            video_name = row['participant_id'] + row['video_id']\n",
    "            filename = video_name + str(i).zfill(3)\n",
    "            if filename in no_filenames:\n",
    "                continue\n",
    "            frame_path = '<PATH>/Images_Original/' + row['participant_id'] + '/' + video_name + '/' + filename + '.png'\n",
    "            frame = cv2.imread(frame_path)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.transform:\n",
    "                frame = transform(frame)\n",
    "            frames.append(frame)\n",
    "\n",
    "        while len(frames) < 4:\n",
    "            frames.insert(0, frames[0])\n",
    "\n",
    "        stacked_frames = torch.stack(frames, dim=1)\n",
    "\n",
    "        label = self.frames_label_df.iloc[idx]['Label']\n",
    "\n",
    "        return stacked_frames, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489bee8c-cfa5-4bf4-8dfe-adcdf800cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset for BioVid on video-lvl\n",
    "class BioVidTestDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.dataset_path = \"<PATH>/BioVid\"\n",
    "        self.transform = transform\n",
    "        self.subjects = [subject for subject in sorted(os.listdir(self.dataset_path)) if subject != \".DS_Store\"]\n",
    "\n",
    "        self.csv_filename = \"<PATH>/dataset_bv.csv\"\n",
    "        self.data = self.read_csv()\n",
    "\n",
    "    def read_csv(self):\n",
    "        data = []\n",
    "        excluded_samples = {'080609_w_27_BL1_98_frame62', '080609_w_27_BL1_98_frame87', '101216_m_40_BL1_100_frame87',\n",
    "                            '101216_m_40_BL1_100_frame112', '101216_m_40_BL1_100_frame137',\n",
    "                            '101814_m_58_PA3_14_frame100', '101814_m_58_PA3_14_frame125', '101814_m_58_PA4_22_frame125'}\n",
    "\n",
    "        with open(self.csv_filename, 'r') as csvfile:\n",
    "            csv_reader = csv.reader(csvfile)\n",
    "            next(csv_reader)  # Skip header row\n",
    "            for row in csv_reader:\n",
    "                sample_name, label = row\n",
    "                if sample_name not in excluded_samples:\n",
    "                    data.append((sample_name, int(label)))\n",
    "        return data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_name, label = self.data[idx]\n",
    "\n",
    "        split_sample_name = sample_name.split(\"_\")\n",
    "        subject_id = f\"{split_sample_name[0]}_{split_sample_name[1]}_{split_sample_name[2]}\"\n",
    "        class_id = split_sample_name[3]\n",
    "\n",
    "        file_path_subject = os.path.join(self.dataset_path, subject_id)\n",
    "        file_path_class = os.path.join(file_path_subject, class_id)\n",
    "\n",
    "        # Load and stack the four subframes\n",
    "        subframes = []\n",
    "        for subframe_num in range(1, 5):\n",
    "            subframe_name = f\"{sample_name}_subframe_{subframe_num}.jpg\"\n",
    "            subframe_path = os.path.join(file_path_class, subframe_name)\n",
    "            subframe = Image.open(subframe_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                subframe = self.transform(subframe)\n",
    "            subframes.append(subframe)\n",
    "\n",
    "        stacked_frames = torch.stack(subframes, dim=1)\n",
    "\n",
    "        return stacked_frames, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a62a3",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7d737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build function for VST model architecture\n",
    "def build_model(unfreezed_layers = 0,  num_classes=2):\n",
    "    # PRETRAINED WITH KINETICS400_V1\n",
    "    model = video_torch.swin3d_s(weights='DEFAULT')\n",
    "\n",
    "    # Freeze all parameters first\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if unfreezed_layers == 0:\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 2:\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 4:\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][17].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][16].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # 4 BUT WITHOUT PATCHING MATCH\n",
    "    if unfreezed_layers == 5:\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        #for param in model.features[5].parameters():\n",
    "        #    param.requires_grad = True\n",
    "        for param in model.features[4][17].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][16].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 6:\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][17].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][16].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][15].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][14].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 8:\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][17].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][16].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][15].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][14].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][13].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][12].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 10:\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in model.features[4][17].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][16].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][15].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][14].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][13].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][12].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][11].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4][10].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 99:\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[4].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "    model.head = nn.Linear(\n",
    "        in_features=768,\n",
    "        out_features= num_classes,\n",
    "        bias=True\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432445e2-d958-4a84-8b32-dc25bbb7216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build function for Swin model (2D) architecture\n",
    "def build_2Dswin_model(unfreezed_layers=0, num_classes=2):\n",
    "\n",
    "    # PRETRAINED WITH IMAGENET1K_V1\n",
    "    model = models.swin_s(weights='DEFAULT')\n",
    "\n",
    "    # Freeze all parameters first\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if unfreezed_layers == 0:\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 2:\n",
    "        for param in model.features[7].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 4:\n",
    "        for param in model.features[7].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][17].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][16].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 6:\n",
    "        for param in model.features[7].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][17].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][16].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][15].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][14].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 8:\n",
    "        for param in model.features[7].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][17].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][16].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][15].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][14].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][13].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.features[5][12].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    model.head = nn.Linear(\n",
    "        in_features=768,\n",
    "        out_features=num_classes,\n",
    "        bias=True\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95245d-ac46-478c-8eeb-167658a3f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build function for ViT model (2D) architecture\n",
    "def build_model_vit(unfreezed_layers = 0,  num_classes=2):\n",
    "    # PRETRAINED WITH IMAGENET1K_V1\n",
    "    model = (models.vit_b_16(weights='DEFAULT'))\n",
    "\n",
    "    model.heads = nn.Linear(\n",
    "        in_features=768,\n",
    "        out_features=num_classes,\n",
    "        bias=True\n",
    "    )\n",
    "\n",
    "    # Freeze all parameters first\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.heads.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 0:\n",
    "        pass\n",
    "\n",
    "    if unfreezed_layers == 2:\n",
    "        for param in model.encoder.layers[11].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[10].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 4:\n",
    "        for param in model.encoder.layers[11].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[10].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[9].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[8].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 6:\n",
    "        for param in model.encoder.layers[11].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[10].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[9].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[8].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[7].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[6].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if unfreezed_layers == 8:\n",
    "        for param in model.encoder.layers[11].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[10].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[9].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[8].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[7].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[6].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[5].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.encoder.layers[4].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd6dd4",
   "metadata": {},
   "source": [
    "## Training functions for a single fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4507a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_single_fold(fold, top, training_optimizer, learning_rate, batches_size, layers, wd, model_type, device):\n",
    "\n",
    "    # CEL as loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Focal Loss \n",
    "    # criterion = kornia.losses.focal_loss(pred=outputs, target=labels, alpha=alpha, gamma=gamma, reduction=\"mean\")\n",
    "\n",
    "    # Load datasets\n",
    "    if model_type == \"vst_3d\":\n",
    "        model = build_model(unfreezed_layers=layers, num_classes=2)\n",
    "        train_ds = VideoFramesDataset(\"train\", fold, 4, transform)\n",
    "        test_ds = VideoFramesDataset(\"test\", fold, 4, transform)\n",
    "    else:\n",
    "        train_ds = FramesDataset(\"train\", fold, transform)\n",
    "        test_ds = FramesDataset(\"test\", fold, transform)\n",
    "        if model_type == \"swin_2d\":\n",
    "            model = build_2Dswin_model(unfreezed_layers=layers, num_classes=2)\n",
    "        elif model_type == \"vit\":\n",
    "            model = build_model_vit(unfreezed_layers=layers, num_classes=2)\n",
    "\n",
    "    model.to(device)\n",
    "    # pain class is over-sampled to prevent overfitting on the majority class\n",
    "    weight_sampler = WeightedRandomSampler(weights=train_ds.weight, num_samples=len(train_ds), replacement=True)\n",
    "\n",
    "    # set up the data loader\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batches_size, num_workers=WORKERS, sampler=weight_sampler, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batches_size, num_workers=WORKERS, shuffle=False)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=wd)\n",
    "\n",
    "    all_epoch_results = []\n",
    "    # training start\n",
    "    print(f\"Model type:{model_type}, Opt: {training_optimizer}, learning_rate: {learning_rate}, batch_size: {batches_size}, Unfreezed layers (except head): {layers}, weight decay:{wd}\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        start = time()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for b, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        # Evaluation\n",
    "        f1, auc = evaluation(model, test_loader, device)\n",
    "        all_epoch_results.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"f1\": f1,\n",
    "            \"auc\": auc\n",
    "        })\n",
    "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {running_loss / len(train_loader)}, F1: {f1}, AUC: {auc}\")\n",
    "        end = time()\n",
    "        time_epoch = end - start\n",
    "        print(\"Finish \" + str(epoch + 1) + \" in \" + str(time_epoch) + \"sec.\")\n",
    "\n",
    "    f = 99\n",
    "    if fold == [\"bn080\", \"mg101\", \"aa048\", \"jh043\", \"jh123\"]:\n",
    "        f = 1\n",
    "    if fold == [\"dn124\", \"vw121\", \"fn059\", \"dr052\", \"ll042\"]:\n",
    "        f = 2\n",
    "    if fold == [\"jk103\", \"jl047\", \"ch092\", \"jy115\", \"bg096\"]:\n",
    "        f = 3\n",
    "    if fold == [\"bm049\", \"kz120\", \"th108\", \"tv095\", \"ib109\"]:\n",
    "        f = 4\n",
    "    if fold == [\"nm106\", \"mg066\", \"hs107\", \"gf097\", \"ak064\"]:\n",
    "        f = 5\n",
    "\n",
    "    ### Save results ###\n",
    "\n",
    "    return f1, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8319a6-8e07-43f5-861b-61b65a9de1b4",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning/Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e30536-ea7c-41bf-95a6-de44333a808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optuna_search_vst(trial, inner_fold, outer_k, temporal_depth):\n",
    "\n",
    "    # Define hyperparameter space\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    unfreezed_layers = trial.suggest_int(\"unfreezed_layers\", 0, 8, step=2)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32])\n",
    "    gamme = trial.suggest_float(\"gamma\", 1, 3, step= 0.5)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.6, 0.95, step=0.05)\n",
    "    loss_fct = \"focal_loss\"\n",
    "\n",
    "    if loss_fct == \"focal_loss\":\n",
    "        criterion = kornia.losses\n",
    "    elif loss_fct == \"cross_entropy_loss\":\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer\")\n",
    "\n",
    "    sum_f1 = 0.0\n",
    "\n",
    "    for j, inner_k in enumerate(inner_fold):\n",
    "        start = time()\n",
    "\n",
    "        model = build_model(unfreezed_layers=unfreezed_layers, num_classes=2)\n",
    "        model.to(device)\n",
    "\n",
    "        k_train_exclude = inner_k + outer_k\n",
    "\n",
    "        train_ds = VideoFramesDataset(\"train\", k_train_exclude, temporal_depth, transform)\n",
    "        test_ds = VideoFramesDataset(\"test\", inner_k, temporal_depth, transform)\n",
    "\n",
    "        if loss_fct == \"focal_loss\":\n",
    "            weight_sampler = None\n",
    "        else:\n",
    "            # pain class is over-sampled to prevent overfitting on the majority class\n",
    "            weight_sampler = WeightedRandomSampler(weights=train_ds.weight, num_samples=len(train_ds), replacement=True)\n",
    "        train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, num_workers=WORKERS, sampler=weight_sampler, shuffle=False)\n",
    "        test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, num_workers=WORKERS, shuffle=False)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "        for epoch in range(1):\n",
    "            model.train()\n",
    "            for b, data in enumerate(train_loader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                labels = labels.long()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                if loss_fct == \"focal_loss\":\n",
    "                    loss = criterion.focal_loss(pred=outputs, target=labels, alpha=alpha, gamma=gamme, reduction=\"mean\")\n",
    "                    #if b % 100 == 0 and b != 0:\n",
    "                    #    print(b, \" loss: \", loss.item())\n",
    "                else:\n",
    "                    loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        f1, _ = evaluation(model, test_loader, device)\n",
    "        sum_f1 += f1\n",
    "\n",
    "        end = time()\n",
    "        diff = end - start\n",
    "\n",
    "        print(\"Time for one epoch: \" + str(diff))\n",
    "\n",
    "    avg_f1 = sum_f1/4\n",
    "    return avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827841ae-42dc-4e1a-ad6e-a05618d4bcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_nested_cv():\n",
    "\n",
    "    # Loop over all 5 folds and do for each a hyperparameter search\n",
    "    for i, outer in enumerate(folds):\n",
    "        print(\"Fold \" + str(i+1))\n",
    "        inner_folds = [fold for fold in folds if fold != outer]\n",
    "        study = optuna.create_study(study_name=f'Baseline VST Focal Loss Optimization Fold {i+1}', direction='maximize',sampler=optuna.samplers.TPESampler())\n",
    "        # Run hyperparameter study\n",
    "        study.optimize(lambda trial: hyperparameter_optuna_search_vst(trial, inner_folds, outer, 4), n_trials=20, n_jobs=1)\n",
    "        # Print best score achieved during conducted hyperparameter study\n",
    "        print('Best Score: ', study.best_trial.value)\n",
    "        # Print best hyperparameter configuration that were used for obtaining the best value during hyperparameter study\n",
    "        print(\"Best Params: \")\n",
    "        for hyperparameter, value in study.best_trial.params.items():\n",
    "            print(\"  {}: {}\".format(hyperparameter, value))\n",
    "        joblib.dump(study, f'<PATH>/optuna_study_batch_fold{i + 1}_vst_focal_loss.pkl')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d121463",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d6a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function (F1, AUC)\n",
    "def evaluation(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_pos_output = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            pos_out = outputs[:,1]\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_pos_output.extend(pos_out.cpu().numpy())\n",
    "\n",
    "    f1_pos_0 = f1_score(all_labels, all_preds, pos_label=1)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_pos_output)\n",
    "    except:\n",
    "        auc = 9999\n",
    "\n",
    "    return f1_pos_0, auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
